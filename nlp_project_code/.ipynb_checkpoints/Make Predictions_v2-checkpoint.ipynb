{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Make Predictions\n",
    "\n",
    "* Compare to fine grain, S system, recall results\n",
    "* I think recall is defined as percentage of correct answers on all instances in test set. Which is what we are doing (basically accuracy)\n",
    "    * http://www2.denizyuret.com/ref/edmonds/senseval.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from __future__ import division\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class WSD:\n",
    "    \n",
    "    model_rf = RandomForestClassifier(n_estimators=10)\n",
    "    model_svm = SVC(kernel='linear', probability=True)\n",
    "    \n",
    "    def __init__(self, lex, n_iter=10):\n",
    "        self.lex = lex\n",
    "        self.n_iter = n_iter\n",
    "        \n",
    "    def _load_data(self, final_dir = \"/Users/tylerfolkman/GradSchool/Spring2015/NLP/project/clean/data/test_train\",\n",
    "                 sem_dir = \"../data/sem_data/\"):\n",
    "        self.train_X = np.load(\"{0}/{1}_train_X.npy\".format(final_dir, self.lex))\n",
    "        self.test_X = np.load(\"{0}/{1}_test_X.npy\".format(final_dir, self.lex))\n",
    "        self.train_target = np.load(\"{0}/{1}_train_target.npy\".format(final_dir, self.lex))\n",
    "        self.test_target = np.load(\"{0}/{1}_test_target.npy\".format(final_dir, self.lex))\n",
    "\n",
    "        self.sem_train_X = np.load(\"{0}/{1}_train_sem.npy\".format(sem_dir, self.lex))\n",
    "        self.sem_test_X = np.load(\"{0}/{1}_test_sem.npy\".format(sem_dir, self.lex))\n",
    "        \n",
    "        self.comb_train_X = np.concatenate([self.train_X, self.sem_train_X], axis=1)\n",
    "        self.comb_test_X = np.concatenate([self.test_X, self.sem_test_X], axis=1)\n",
    "        \n",
    "    def _fit(self, X, y):\n",
    "        self.model_rf.fit(X, y)\n",
    "        self.model_svm.fit(X, y)\n",
    "        self.fimport = self.model_rf.feature_importances_\n",
    "        \n",
    "    def _predict(self, X):\n",
    "        pred_rf_prob = self.model_rf.predict_proba(X)\n",
    "        pred_svm_prob = self.model_svm.predict_proba(X)\n",
    "        \n",
    "        both_max = np.maximum(pred_rf_prob, pred_svm_prob).argmax(axis=1)\n",
    "        both_mean = np.mean( np.array([ pred_rf_prob, pred_svm_prob ]), axis=0 ).argmax(axis=1)\n",
    "        rf_max = pred_rf_prob.argmax(axis=1)\n",
    "        svm_max = pred_svm_prob.argmax(axis=1)\n",
    "        \n",
    "        self.pred_rf = self._get_classes(rf_max)\n",
    "        self.pred_svm = self._get_classes(svm_max)\n",
    "        self.pred_max = self._get_classes(both_max)\n",
    "        self.pred_mean = self._get_classes(both_mean)\n",
    "        \n",
    "    def _get_classes(self, arg_list):\n",
    "        assert np.array_equal(self.model_rf.classes_, self.model_svm.classes_)\n",
    "        pred_classes = []\n",
    "        for a in arg_list:\n",
    "            pred_classes.append(self.model_rf.classes_[a])\n",
    "        return np.array(pred_classes)\n",
    "        \n",
    "    def _get_acc(self, y_pred):\n",
    "        tp = 0\n",
    "        for i, y in enumerate(self.test_target):\n",
    "            if y_pred[i] in y:\n",
    "                tp = tp+1\n",
    "        return tp / len(y_pred)\n",
    "    \n",
    "    def _run_model(self, train_X, test_X):\n",
    "        acc_dict = defaultdict(list)\n",
    "        for i in range(self.n_iter):\n",
    "            self._fit(train_X, self.train_target)\n",
    "            self._predict(test_X)\n",
    "            rf_acc = self._get_acc(self.pred_rf)\n",
    "            svm_acc = self._get_acc(self.pred_svm)\n",
    "            max_acc = self._get_acc(self.pred_max)\n",
    "            mean_acc = self._get_acc(self.pred_mean)\n",
    "            acc_dict['randomForest'].append(rf_acc)\n",
    "            acc_dict['svm'].append(svm_acc)\n",
    "            acc_dict['both_max'].append(max_acc)\n",
    "            acc_dict['both_mean'].append(mean_acc)\n",
    "        return acc_dict\n",
    "    \n",
    "    def _run_all_models(self):\n",
    "        self._load_data()\n",
    "        model_dict = defaultdict(dict)\n",
    "        model_dict['syntax'] = self._run_model(self.train_X, self.test_X)\n",
    "        model_dict['semantics'] = self._run_model(self.sem_train_X, self.sem_test_X)\n",
    "        model_dict['combined'] = self._run_model(self.comb_train_X, self.comb_test_X)\n",
    "        self.model_dict = model_dict\n",
    "    \n",
    "    def _to_df(self):\n",
    "        self.df = pd.DataFrame.from_dict(self.model_dict, orient='index')\n",
    "    \n",
    "    def run_all_df(self):\n",
    "        self._run_all_models()\n",
    "        self._to_df()\n",
    "        return self.fimport, self.df\n",
    "    \n",
    "    def run_all_save(self, dir_out=\"../data/predictions/\"):\n",
    "        self._run_all_models()\n",
    "        self._to_df()\n",
    "        self.df.to_csv(dir_out + self.lex + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excessn = WSD('excess-n')\n",
    "fimport , df = excessn.run_all_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Container object of 10 artists>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEACAYAAABS29YJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAD1tJREFUeJzt3X+o3Xd9x/Hnyxs77WQLw9Ha5kJlTaGViRGpYbotThnh\n",
       "IulgsBomlTJsYGZ2/iFd/WPGv7Z/hq6UlWxWidOZjeokYrT+DAhCtJjGH0lcMxeWpDSKWjc7Bsl8\n",
       "74/zTXt7zD0/cu8935N8ng+45Hw/38/3nPe93PvK53zO9/P9pqqQJF3dXtB3AZKk9WfYS1IDDHtJ\n",
       "aoBhL0kNMOwlqQGGvSQ1YGzYJ9me5ESSJ5Lct0KfB7r9R5NsWdZ+Ksm3khxJ8vW1LFySNLkNo3Ym\n",
       "WQAeBN4EnAW+keRAVR1f1mcJuLmqNid5LfAQsLXbXcC2qvrxulQvSZrIuJH97cDJqjpVVeeB/cAd\n",
       "Q312APsAquowsDHJdcv2Z62KlSRdnnFhfyNwetn2ma5t0j4FfDHJY0nevppCJUmXb+Q0DoOwnsRK\n",
       "o/fXV9WTSX4d+EKSE1X11cnLkySthXFhfxZYXLa9yGDkPqrPpq6Nqnqy+/eHSf6VwbTQ88I+iRfn\n",
       "kaTLUFUTT5OPC/vHgM1JbgKeBO4Edg71OQDsBvYn2Qo8XVXnklwLLFTVfyf5ZeD3gfettuCrWZI9\n",
       "VbWn7zrmgT+L5/izeI4/i+dMO1AeGfZVdSHJbuBRYAF4uKqOJ9nV7d9bVQeTLCU5CTwD3N0dfj3w\n",
       "ySQXX+djVfX56b4dSdJaGDeyp6o+C3x2qG3v0PbuSxz3feBVqy1QkrR6rqCdL4f6LmCOHOq7gDly\n",
       "qO8C5sihvgu4UqXvm5ckKefsJWk602anI3tJaoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUgLGLqmZh\n",
       "ltfH8TRPSS2ai7Cf/OKaq2XOS2qT0ziS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWpAYa9JDXAsJek\n",
       "Bhj2ktQAw16SGmDYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWqA\n",
       "YS9JDdjQdwHzIknN8vWqKrN8PUltM+yfZ1Z5b85Lmi2ncSSpAYa9JDXAsJekBowN+yTbk5xI8kSS\n",
       "+1bo80C3/2iSLUP7FpIcSfLptSpakjSdkWGfZAF4ENgO3AbsTHLrUJ8l4Oaq2gzcAzw09DT3AseY\n",
       "3aefkqQh40b2twMnq+pUVZ0H9gN3DPXZAewDqKrDwMYk1wEk2QQsAR/EU1AkqTfjwv5G4PSy7TNd\n",
       "26R93g+8G/j5KmqUJK3SuPPsJ516GR61J8mbgR9U1ZEk20YfvmfZ423dlyTpoi5Ht13u8ePC/iyw\n",
       "uGx7kcHIfVSfTV3bHwI7ujn9FwG/kuQjVXXXL77MnqmKlqTWVNUh4NDF7STvneb4cdM4jwGbk9yU\n",
       "5BrgTuDAUJ8DwF3di28Fnq6qp6rqPVW1WFUvB94CfPnSQS9JWm8jR/ZVdSHJbuBRYAF4uKqOJ9nV\n",
       "7d9bVQeTLCU5CTwD3L3S061l4ZKkyaWq3wweXIBsdtekWekCZPNQhxdjkzSpJDXN37AXQps7XoxN\n",
       "0trzcgmS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWpAYa9JDXAsJekBhj2ktQAw16SGmDYS1IDDHtJ\n",
       "aoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDTDsJakBhr0kNcCwl6QG\n",
       "GPaS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWpAYa9JDXAsJekBhj2ktQAw16SGjA27JNsT3IiyRNJ\n",
       "7luhzwPd/qNJtnRtL0pyOMnjSY4l+au1Ll6SNJmRYZ9kAXgQ2A7cBuxMcutQnyXg5qraDNwDPARQ\n",
       "Vf8LvKGqXgW8EnhDktev/bcgSRpn3Mj+duBkVZ2qqvPAfuCOoT47gH0AVXUY2Jjkum77f7o+1wAL\n",
       "wI/XqnBJ0uTGhf2NwOll22e6tnF9NsHgnUGSx4FzwFeq6tjqypUkXY5xYV8TPk8udVxV/V83jbMJ\n",
       "+J0k26YrT5K0FjaM2X8WWFy2vchg5D6qz6au7VlV9dMknwFeAxz6xZfZs+zxtu5LknRRN1jedtnH\n",
       "V608eE+yAfge8EbgSeDrwM6qOr6szxKwu6qWkmwFPlBVW5O8FLhQVU8neTHwKPC+qvrS0GvU5G8g\n",
       "VitU1fC7kLmpYx5qkHRlSFLT/A2PHNlX1YUkuxkE9QLwcFUdT7Kr27+3qg4mWUpyEngGuLs7/GXA\n",
       "viQvYDBd9I/DQS9Jmo2RI/uZFDAno9l5qGMeapB0ZZh2ZO8KWklqgGEvSQ0w7CWpAYa9JDXAsJek\n",
       "Bhj2ktQAw16SGmDYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWrA\n",
       "uBuOq0GDO2bNjnfMktafYa8VzO72iJLWn9M4ktQAw16SGmDYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1\n",
       "wPPsNZdc2CWtLcNec8yFXdJacRpHkhpg2EtSAwx7SWqAYS9JDTDsJakBhr0kNcCwl6QGGPaS1ICJ\n",
       "wj7J9iQnkjyR5L4V+jzQ7T+aZEvXtpjkK0m+m+Q7Sd65lsVLkiYzNuyTLAAPAtuB24CdSW4d6rME\n",
       "3FxVm4F7gIe6XeeBd1XVK4CtwDuGj5Ukrb9JRva3Ayer6lRVnQf2A3cM9dkB7AOoqsPAxiTXVdVT\n",
       "VfV41/4z4Dhww5pVL0mayCTXxrkROL1s+wzw2gn6bALOXWxIchOwBTh8GXVKvZjlBdm8GJvW0yRh\n",
       "P+kv+/Av6rPHJXkJ8AhwbzfCl64gs8h7c17ra5KwPwssLtteZDByH9VnU9dGkhcCnwA+WlWfuvRL\n",
       "7Fn2eFv3JUm6KMk2VhGOqRo9akmyAfge8EbgSeDrwM6qOr6szxKwu6qWkmwFPlBVW5OEwVz+j6rq\n",
       "XSs8f83yUrYrvVWehzrmoYZ5qWMeaphtHSvXIF1Kkprmd2bsyL6qLiTZDTwKLAAPV9XxJLu6/Xur\n",
       "6mCSpSQngWeAu7vDXwe8FfhWkiNd2/1V9bkpvidJ0iqNHdmvewHNjeBWrmMeapiXOuahhtnW4che\n",
       "05l2ZO8KWklqgGEvSQ0w7CWpAYa9JDVgkvPsJfVolqt4wZW8VyvDXroizO7MJF2dnMaRpAYY9pLU\n",
       "AMNekhpg2EtSAwx7SWqAYS9JDTDsJakBhr0kNcCwl6QGuIJW0kS8+fqVzbCXNAVvvn6lchpHkhpg\n",
       "2EtSA5zGkXTF8HLPl8+wl3SF8XLPl8Owl6QpXYlnJhn2knRZrqwzk/yAVpIaYNhLUgMMe0lqgGEv\n",
       "SQ0w7CWpAYa9JDXAsJekBhj2ktQAw16SGmDYS1IDDHtJaoBhL0kNMOwlqQFjwz7J9iQnkjyR5L4V\n",
       "+jzQ7T+aZMuy9g8lOZfk22tZtCRpOiPDPskC8CCwHbgN2Jnk1qE+S8DNVbUZuAd4aNnuD3fHSpJ6\n",
       "NG5kfztwsqpOVdV5YD9wx1CfHcA+gKo6DGxMcn23/VXgJ2tbsiRpWuPC/kbg9LLtM13btH0kST0a\n",
       "d6eqSW/FMnw7lSlv4bJn2eNt3Zck6aIk21hFOI4L+7PA4rLtRQYj91F9NnVtU9gzXXdJakxVHQIO\n",
       "XdxO8t5pjh83jfMYsDnJTUmuAe4EDgz1OQDc1b34VuDpqjo3TRGSpPU1Muyr6gKwG3gUOAb8c1Ud\n",
       "T7Irya6uz0Hg+0lOAnuBP714fJKPA18DbklyOsnd6/R9SJJGSNUs7pA+ooCkZnOXdoBQVZe8Xfs8\n",
       "1DEPNcxLHfNQw2zrmIca5qWOeahhXuoYXcNK+y7FFbSS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWp\n",
       "AYa9JDXAsJekBhj2ktQAw16SGmDYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg\n",
       "2EtSAwx7SWqAYS9JDTDsJakBhr0kNcCwl6QGGPaS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWpAYa9\n",
       "JDXAsJekBhj2ktQAw16SGmDYS1IDxoZ9ku1JTiR5Isl9K/R5oNt/NMmWaY6VJK2/kWGfZAF4ENgO\n",
       "3AbsTHLrUJ8l4Oaq2gzcAzw06bGSpNkYN7K/HThZVaeq6jywH7hjqM8OYB9AVR0GNia5fsJjJUkz\n",
       "MC7sbwROL9s+07VN0ueGCY6VJM3AuLCvCZ8nqy1EkrR+NozZfxZYXLa9yGCEPqrPpq7PCyc4tjO7\n",
       "/yuSjPgPbB7qmIca5qWOeahhdnXMQw3zUsc81DAvdYyuYXLjwv4xYHOSm4AngTuBnUN9DgC7gf1J\n",
       "tgJPV9W5JD+a4FiqyncFkrTORoZ9VV1Isht4FFgAHq6q40l2dfv3VtXBJEtJTgLPAHePOnY9vxlJ\n",
       "0qWlak3eIUiS5livK2hddDWQZDHJV5J8N8l3kryz75r6lmQhyZEkn+67lj4l2ZjkkSTHkxzrpkqb\n",
       "lOT+7m/k20n+Kckv9V3TrCT5UJJzSb69rO3Xknwhyb8l+XySjaOeo7ewd9HV85wH3lVVrwC2Au9o\n",
       "+Gdx0b3AMSY/I+xq9bfAwaq6FXgl0ORUaPfZ39uBV1fVbzKYGn5LnzXN2IcZZOVyfwF8oapuAb7U\n",
       "ba+oz5G9i646VfVUVT3ePf4Zgz/oG/qtqj9JNgFLwAdp+LTeJL8K/HZVfQgGn4NV1U97Lqsv/8Vg\n",
       "UHRtkg3AtQzOBGxCVX0V+MlQ87MLWrt//2DUc/QZ9pMs2GpON4LZAhzut5JevR94N/Dzvgvp2cuB\n",
       "Hyb5cJJvJvmHJNf2XVQfqurHwN8A/8ng7L6nq+qL/VbVu+uq6lz3+Bxw3ajOfYZ962/Pf0GSlwCP\n",
       "APd2I/zmJHkz8IOqOkLDo/rOBuDVwN9V1asZnO028q361SrJbwB/DtzE4F3vS5L8ca9FzZEanGkz\n",
       "MlP7DPtJFmw1I8kLgU8AH62qT/VdT49+C9iR5D+AjwO/l+QjPdfUlzPAmar6Rrf9CIPwb9FrgK9V\n",
       "1Y+q6gLwSQa/Ky07112HjCQvA34wqnOfYf/sgq0k1zBYdHWgx3p6kyTAw8CxqvpA3/X0qareU1WL\n",
       "VfVyBh/Afbmq7uq7rj5U1VPA6SS3dE1vAr7bY0l9OgFsTfLi7u/lTQw+wG/ZAeBt3eO3ASMHieNW\n",
       "0K4bF109z+uAtwLfSnKka7u/qj7XY03zovXpvj8DPtYNiP6dbtFia6rqaPcO7zEGn+V8E/j7fqua\n",
       "nSQfB34XeGmS08BfAn8N/EuSPwFOAX808jlcVCVJVz9vSyhJDTDsJakBhr0kNcCwl6QGGPaS1ADD\n",
       "XpIaYNhLUgMMe0lqwP8DdxuT7jeh1DsAAAAASUVORK5CYII=\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13c075910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "order = np.sort(fimport)[::-1][:10]\n",
    "plt.bar(range(len(order)), order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excessn = WSD('excess-n')\n",
    "excessn.run_all_save()\n",
    "\n",
    "floatv = WSD('float-v')\n",
    "floatv.run_all_save()\n",
    "\n",
    "brillianta = WSD('brilliant-a')\n",
    "brillianta.run_all_save()\n",
    "\n",
    "accidentn = WSD('accident-n')\n",
    "accidentn.run_all_save()\n",
    "\n",
    "promisev = WSD('promise-v')\n",
    "promisev.run_all_save()\n",
    "\n",
    "generousa = WSD('generous-a')\n",
    "generousa.run_all_save()\n",
    "\n",
    "botherv = WSD('bother-v')\n",
    "botherv.run_all_save()\n",
    "\n",
    "derivev = WSD('derive-v')\n",
    "derivev.run_all_save()\n",
    "\n",
    "sackn = WSD('sack-n')\n",
    "sackn.run_all_save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
